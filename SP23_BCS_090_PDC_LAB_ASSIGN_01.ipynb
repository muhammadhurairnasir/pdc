{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YVNCvYxoVis",
        "outputId": "677660b9-223f-4824-b434-091f4c46dddc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.12/dist-packages (2025.1.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.12/dist-packages (from pycuda) (2025.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycuda) (4.4.0)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.12/dist-packages (from pycuda) (1.3.10)\n",
            "Requirement already satisfied: siphash24>=1.6 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (1.8)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from mako->pycuda) (3.0.2)\n",
            "=== Hello from GPU threads ===\n",
            "Hello from thread 0\n",
            "Hello from thread 1\n",
            "Hello from thread 2\n",
            "Hello from thread 3\n",
            "Hello from thread 4\n",
            "Hello from thread 5\n",
            "Hello from thread 6\n",
            "Hello from thread 7\n"
          ]
        }
      ],
      "source": [
        "!pip install pycuda\n",
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "import pycuda.gpuarray as gpuarray\n",
        "from pycuda.compiler import SourceModule\n",
        "# CUDA kernel\n",
        "kernel_code = \"\"\"\n",
        "__global__ void hello(int *out)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    out[tid] = tid;  // write thread ID\n",
        "}\n",
        "\"\"\"\n",
        "# Compile\n",
        "mod = SourceModule(kernel_code)\n",
        "hello = mod.get_function(\"hello\")\n",
        "# Prepare GPU array (8 threads total)\n",
        "n_threads = 8\n",
        "out_gpu = gpuarray.zeros(n_threads, dtype=np.int32)\n",
        "# Launch <<<2,4>>>\n",
        "hello(out_gpu, block=(4,1,1), grid=(2,1))\n",
        "# Copy back and print\n",
        "print(\"=== Hello from GPU threads ===\")\n",
        "for tid in out_gpu.get():   # .get() copies back to host\n",
        "    print(f\"Hello from thread {tid}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda\n",
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "from pycuda.compiler import SourceModule\n",
        "import time\n",
        "\n",
        "# CUDA kernel\n",
        "kernel_code = \"\"\"\n",
        "__global__ void vector_add(float *a, float *b, float *c, int n)\n",
        "{\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (idx < n) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "mod = SourceModule(kernel_code)\n",
        "vector_add = mod.get_function(\"vector_add\")\n",
        "\n",
        "# Problem size\n",
        "N = 10_000_000\n",
        "a = np.random.rand(N).astype(np.float32)\n",
        "b = np.random.rand(N).astype(np.float32)\n",
        "c = np.zeros_like(a)\n",
        "\n",
        "# Allocate GPU memory\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "# Copy to GPU\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "# CPU timing\n",
        "start = time.time()\n",
        "c_cpu = a + b\n",
        "cpu_time = time.time() - start\n",
        "print(f\"CPU Time: {cpu_time:.4f} sec\")\n",
        "\n",
        "# GPU timing\n",
        "threads_per_block = 256\n",
        "blocks_per_grid = (N + threads_per_block - 1) // threads_per_block\n",
        "\n",
        "start = time.time()\n",
        "vector_add(a_gpu, b_gpu, c_gpu, np.int32(N),\n",
        "           block=(threads_per_block,1,1), grid=(blocks_per_grid,1))\n",
        "cuda.Context.synchronize()\n",
        "gpu_time = time.time() - start\n",
        "print(f\"GPU Time: {gpu_time:.4f} sec\")\n",
        "\n",
        "# Copy back\n",
        "cuda.memcpy_dtoh(c, c_gpu)\n",
        "\n",
        "# Verify correctness\n",
        "print(\"Results match:\", np.allclose(c, c_cpu))\n",
        "\n",
        "# Speedup\n",
        "speedup = cpu_time / gpu_time\n",
        "print(f\"Speedup = {speedup:.2f}x\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpcoiX2MuU_O",
        "outputId": "b526bf69-b1e7-486a-eb54-be25c336920c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.12/dist-packages (2025.1.2)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.12/dist-packages (from pycuda) (2025.2.4)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from pycuda) (4.4.0)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.12/dist-packages (from pycuda) (1.3.10)\n",
            "Requirement already satisfied: siphash24>=1.6 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (1.8)\n",
            "Requirement already satisfied: typing-extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from pytools>=2011.2->pycuda) (4.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from mako->pycuda) (3.0.2)\n",
            "CPU Time: 0.0170 sec\n",
            "GPU Time: 0.0007 sec\n",
            "Results match: True\n",
            "Speedup = 23.89x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SAVE AS invert_cupy_test.py\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "# -------------------------\n",
        "# Generate test image (grayscale gradient)\n",
        "# -------------------------\n",
        "H, W = 2048, 2048   # Adjust size if you want\n",
        "gray = np.tile(np.arange(W, dtype=np.uint8), (H, 1))\n",
        "\n",
        "cv2.imwrite(\"test_input.png\", gray)\n",
        "print(f\"Generated test image: {H}x{W}\")\n",
        "\n",
        "# -------------------------\n",
        "# CPU VERSION (explicit loop)\n",
        "# -------------------------\n",
        "cpu_start = time.time()\n",
        "cpu_inverted = np.empty_like(gray)\n",
        "for i in range(H):\n",
        "    for j in range(W):\n",
        "        cpu_inverted[i, j] = 255 - gray[i, j]\n",
        "cpu_time = time.time() - cpu_start\n",
        "print(f\"CPU loop inversion time: {cpu_time:.4f} sec\")\n",
        "\n",
        "# -------------------------\n",
        "# GPU VERSION (CuPy RawKernel)\n",
        "# -------------------------\n",
        "gpu_start = time.time()\n",
        "\n",
        "d_img = cp.array(gray)\n",
        "\n",
        "invert_kernel = cp.RawKernel(r'''\n",
        "extern \"C\" __global__\n",
        "void invert(unsigned char* img, unsigned char* out, int H, int W) {\n",
        "    int x = blockDim.x * blockIdx.x + threadIdx.x;\n",
        "    int y = blockDim.y * blockIdx.y + threadIdx.y;\n",
        "    if (x < W && y < H) {\n",
        "        int idx = y * W + x;\n",
        "        out[idx] = 255 - img[idx];\n",
        "    }\n",
        "}\n",
        "''', \"invert\")\n",
        "\n",
        "d_out = cp.empty_like(d_img)\n",
        "\n",
        "threads = (16, 16)\n",
        "blocks = ((W + threads[0] - 1) // threads[0],\n",
        "          (H + threads[1] - 1) // threads[1])\n",
        "\n",
        "invert_kernel(blocks, threads, (d_img, d_out, H, W))\n",
        "\n",
        "gpu_inverted = d_out.get()\n",
        "gpu_time = time.time() - gpu_start\n",
        "print(f\"GPU inversion time: {gpu_time:.4f} sec\")\n",
        "\n",
        "# -------------------------\n",
        "# Verify correctness\n",
        "# -------------------------\n",
        "diff = np.abs(cpu_inverted.astype(int) - gpu_inverted.astype(int)).sum()\n",
        "print(\"Difference between CPU and GPU outputs:\", diff)\n",
        "\n",
        "# -------------------------\n",
        "# Save results\n",
        "# -------------------------\n",
        "cv2.imwrite(\"cpu_inverted.png\", cpu_inverted)\n",
        "cv2.imwrite(\"gpu_inverted.png\", gpu_inverted)\n",
        "print(\"Saved test_input.png, cpu_inverted.png, and gpu_inverted.png\")\n"
      ],
      "metadata": {
        "id": "usyaCx2muwBy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce7dd81-f611-44af-e4e4-d19db32867e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated test image: 2048x2048\n",
            "CPU loop inversion time: 5.6526 sec\n",
            "GPU inversion time: 1.1336 sec\n",
            "Difference between CPU and GPU outputs: 0\n",
            "Saved test_input.png, cpu_inverted.png, and gpu_inverted.png\n"
          ]
        }
      ]
    }
  ]
}